/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as Vapi from "../index.js";
export interface AnthropicModel {
    /** This is the starting state for the conversation. */
    messages?: Vapi.OpenAiMessage[];
    /**
     * These are the tools that the assistant can use during the call. To use existing tools, use `toolIds`.
     *
     * Both `tools` and `toolIds` can be used together.
     */
    tools?: AnthropicModel.Tools.Item[];
    /**
     * These are the tools that the assistant can use during the call. To use transient tools, use `tools`.
     *
     * Both `tools` and `toolIds` can be used together.
     */
    toolIds?: string[];
    /** These are the options for the knowledge base. */
    knowledgeBase?: Vapi.CreateCustomKnowledgeBaseDto;
    /** This is the ID of the knowledge base the model will use. */
    knowledgeBaseId?: string;
    /** The specific Anthropic/Claude model that will be used. */
    model: AnthropicModel.Model;
    /** The provider identifier for Anthropic. */
    provider: "anthropic";
    /**
     * Optional configuration for Anthropic's thinking feature.
     * Only applicable for claude-3-7-sonnet-20250219 model.
     * If provided, maxTokens must be greater than thinking.budgetTokens.
     */
    thinking?: Vapi.AnthropicThinkingConfig;
    /** This is the temperature that will be used for calls. Default is 0 to leverage caching for lower latency. */
    temperature?: number;
    /** This is the max number of tokens that the assistant will be allowed to generate in each turn of the conversation. Default is 250. */
    maxTokens?: number;
    /**
     * This determines whether we detect user's emotion while they speak and send it as an additional info to model.
     *
     * Default `false` because the model is usually are good at understanding the user's emotion from text.
     *
     * @default false
     */
    emotionRecognitionEnabled?: boolean;
    /**
     * This sets how many turns at the start of the conversation to use a smaller, faster model from the same provider before switching to the primary model. Example, gpt-3.5-turbo if provider is openai.
     *
     * Default is 0.
     *
     * @default 0
     */
    numFastTurns?: number;
}
export declare namespace AnthropicModel {
    type Tools = Tools.Item[];
    namespace Tools {
        type Item = Vapi.CreateApiRequestToolDto | Vapi.CreateBashToolDto | Vapi.CreateComputerToolDto | Vapi.CreateDtmfToolDto | Vapi.CreateEndCallToolDto | Vapi.CreateFunctionToolDto | Vapi.CreateGoHighLevelCalendarAvailabilityToolDto | Vapi.CreateGoHighLevelCalendarEventCreateToolDto | Vapi.CreateGoHighLevelContactCreateToolDto | Vapi.CreateGoHighLevelContactGetToolDto | Vapi.CreateGoogleCalendarCheckAvailabilityToolDto | Vapi.CreateGoogleCalendarCreateEventToolDto | Vapi.CreateGoogleSheetsRowAppendToolDto | Vapi.CreateMcpToolDto | Vapi.CreateQueryToolDto | Vapi.CreateSlackSendMessageToolDto | Vapi.CreateSmsToolDto | Vapi.CreateTextEditorToolDto | Vapi.CreateTransferCallToolDto;
    }
    /**
     * The specific Anthropic/Claude model that will be used.
     */
    type Model = "claude-3-opus-20240229" | "claude-3-sonnet-20240229" | "claude-3-haiku-20240307" | "claude-3-5-sonnet-20240620" | "claude-3-5-sonnet-20241022" | "claude-3-5-haiku-20241022" | "claude-3-7-sonnet-20250219" | "claude-opus-4-20250514" | "claude-sonnet-4-20250514";
    const Model: {
        readonly Claude3Opus20240229: "claude-3-opus-20240229";
        readonly Claude3Sonnet20240229: "claude-3-sonnet-20240229";
        readonly Claude3Haiku20240307: "claude-3-haiku-20240307";
        readonly Claude35Sonnet20240620: "claude-3-5-sonnet-20240620";
        readonly Claude35Sonnet20241022: "claude-3-5-sonnet-20241022";
        readonly Claude35Haiku20241022: "claude-3-5-haiku-20241022";
        readonly Claude37Sonnet20250219: "claude-3-7-sonnet-20250219";
        readonly ClaudeOpus420250514: "claude-opus-4-20250514";
        readonly ClaudeSonnet420250514: "claude-sonnet-4-20250514";
    };
}
